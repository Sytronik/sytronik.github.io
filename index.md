# About Sytronik

**Jeongmin Liu (유정민, 劉政旼)**  
M.S. Candidate, [Smart Sound Systems Laboratory](https://sound.kaist.ac.kr),  
School of Electrical Engineering, KAIST.

**Email**: <sytronik@gmail.com>  
**GitHub**: <https://github.com/Sytronik>

## Interests

- Signal Processing (Multi-channel Audio or Speech)
- Deep Learning / Machine Learning
- Python
- Rust (Programming Language)


## Education

- ME in Electrical Engineering (Candidate)  
  Korea Advanced Institute of Science and Technology (KAIST)

- BE in Electrical Engineering, 2018  
  Pohang University of Science and Technology (POSTECH)

## Papers

### Conference Paper

- Jeongmin Liu, Byeongho Jo, Jung-Woo Choi, **Dereverberation Based on Deep Neural Networks with Directional Feature from Spherical Microphone Array Recordings**, in Proc. of the 23rd International Congress on Acoustics (ICA 2019), Aachen, Germany, September 9-13, 2019. *(accepted)*  
  [Paper](/assets/ICA2019.pdf) | [GitHub Repo](https://github.com/Sytronik/dereverberation-directional-feature)

## Projects

- **End-to-end Multi-channel Speech Dereverberation** *(In Progress)*  
  *July 2019 - now*  
  To research end-to-end speech dereverberation, I firstly implemented speech denoising wavenet with PyTorch. I am researching better end-to-end speech dereverberation algorithm.  
  [GitHub Repo](https://github.com/Sytronik/denoising-wavenet-pytorch)

- **Music Boundary Detection using Fully Convolutional Neural Networks**  
  *May - July 2019*  
  For the team projects in the lecture "Musical Applications of Machine Learning" of KAIST, My team made the DNN model that detects boundaries between musical sections, which have different musical themes. I contributed to the DNN model structure and training techniques, and I implemented them.  
  [Report](/assets/music-boundary-detection-report.pdf) | 
  [GitHub Repo](https://github.com/Sytronik/music-boundary-detection)

- **VR Drum**  
  *2017*  
  For the graduation project, my team created an application that lets people can play the drums in virtual reality. I was the main programmer in the project.  
  [Report (Korean)](/assets/VR-drum-report-korean.pdf) | [Demo Video](https://youtu.be/QXyJwmr9mhQ)

- **Extracting Musical Rhythms from Repetitive Videos**  
  *March - May 2017*  
  To choose rhythmically-matched music to the repetitive videos, I created a simple algorithm. The algorithm extracts a rough temporal regularity from repetitive videos, approximates the regularity to a typical 4/4 rhythm, and inserts a simple rhythm instrument pattern.  
  [Report](/assets/extracting-musical-rhythms-report.pdf) | [Results (.zip)](/assets/extracting-musical-rhythms-results.zip)

## Languages

- 한국어 (모어) / Korean native speaker
- English (good working knowledge)
- 中文 (初學者) / Chinese Mandarin beginner

## Teaching Assistant

### KAIST

- **Signals and Systems** (EE202)  
  *2019 Spring*  
  The basic lecture of signal processing area

- **Electronics Design Lab** (EE405)  
  *2018 Fall*  
  The practice of embedded system programming